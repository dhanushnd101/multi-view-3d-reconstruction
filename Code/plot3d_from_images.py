# -*- coding: utf-8 -*-
"""plot3d_from_images.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1noFFe-TAAnxEe-BnjHGL-4PmRu53GS2-
"""

import os
import sys
import cv2
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
from PIL import Image

from scipy.optimize import least_squares
from skimage.measure import ransac
from skimage.transform import ProjectiveTransform, AffineTransform

def siftMatching(img1, img2):
    # Input : image1 and image2 in opencv format
    # Output : corresponding keypoints for source and target images
    # Output Format : Numpy matrix of shape: [No. of Correspondences X 2] 

    sift = cv2.SIFT_create()
    #kp = sift.detect(img1, None)
    #kp = cv2.SIFT(edgeThreshold=10)
    kp1, des1 = sift.detectAndCompute(img1, None)
    kp2, des2 = sift.detectAndCompute(img2, None)

    FLANN_INDEX_KDTREE = 0
    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
    search_params = dict(checks = 50)
    flann = cv2.FlannBasedMatcher(index_params, search_params)
    matches = flann.knnMatch(des1,des2,k=2)

    # Lowe's Ratio test
    good = []
    for m, n in matches:
        if m.distance < 0.7*n.distance:
            good.append(m)

    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1, 2)
    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1, 2)

    # Ransac
    model, inliers = ransac(
            (src_pts, dst_pts),
            AffineTransform, min_samples=4,
            residual_threshold=8, max_trials=10000
        )

    n_inliers = np.sum(inliers)

    inlier_keypoints_left = [cv2.KeyPoint(point[0], point[1], 1) for point in src_pts[inliers]]
    inlier_keypoints_right = [cv2.KeyPoint(point[0], point[1], 1) for point in dst_pts[inliers]]
    placeholder_matches = [cv2.DMatch(idx, idx, 1) for idx in range(n_inliers)]
    
    # image3 = cv2.drawMatches(img1, inlier_keypoints_left, img2, inlier_keypoints_right, placeholder_matches, None)
    # fig = plt.figure()
    # fig.set_size_inches(18,10)
    # plt.imshow(cv2.cvtColor(image3, cv2.COLOR_BGR2RGB))    

    src_pts = np.float32([ inlier_keypoints_left[m.queryIdx].pt for m in placeholder_matches ]).reshape(-1, 2)
    dst_pts = np.float32([ inlier_keypoints_right[m.trainIdx].pt for m in placeholder_matches ]).reshape(-1, 2)

    return src_pts, dst_pts

def triangulate_nviews(P, ip):
    """
    Triangulate a point visible in n camera views.
    P is a list of camera projection matrices.
    ip is a list of homogenised image points. eg [ [x, y, 1], [x, y, 1] ], OR,
    ip is a 2d array - shape nx3 - [ [x, y, 1], [x, y, 1] ]
    len of ip must be the same as len of P
    """
    if not len(ip) == len(P):
        raise ValueError('Number of points and number of cameras not equal.')
    n = len(P)
    M = np.zeros([3*n, 4+n])
    for i, (x, p) in enumerate(zip(ip, P)):
        M[3*i:3*i+3, :4] = p
        M[3*i:3*i+3, 4+i] = -x
    V = np.linalg.svd(M)[-1]
    X = V[-1, :4]
    return X / X[3]


def triangulate_points(P1, P2, x1, x2):
    """
    Two-view triangulation of points in
    x1,x2 (nx3 homog. coordinates).
    Similar to openCV triangulatePoints.
    """
    if not len(x2) == len(x1):
        raise ValueError("Number of points don't match.")
    X = [triangulate_nviews([P1, P2], [x[0], x[1]]) for x in zip(x1, x2)]
    return np.array(X)

def reprojection_loss_function(opt_variables, points_2d, num_pts):
    '''
    opt_variables --->  Camera Projection matrix + All 3D points
    '''
    P = opt_variables[0:12].reshape(3,4)
    point_3d = opt_variables[12:].reshape((num_pts, 4))

    rep_error = []

    for idx, pt_3d in enumerate(point_3d):
        pt_2d = np.array([points_2d[0][idx], points_2d[1][idx]])

        reprojected_pt = np.matmul(P, pt_3d)
        reprojected_pt /= reprojected_pt[2]
        # print("Reprojection Error \n" + str(pt_2d - reprojected_pt[0:2]))
        rep_error.append(pt_2d - reprojected_pt[0:2])

    return np.array(rep_error).ravel()


def bundle_adjustment(points_3d, points_2d, img, projection_matrix):

    opt_variables = np.hstack((projection_matrix.ravel(), points_3d.ravel(order="F")))
    num_points = len(points_2d[0])

    corrected_values = least_squares(reprojection_loss_function, opt_variables, args=(points_2d,num_points))

#     print("The optimized values \n" + str(corrected_values))
    P = corrected_values.x[0:12].reshape(3,4)
    points_3d = corrected_values.x[12:].reshape((num_points, 4))

    return P, points_3d



"""### Temple dataset"""



P = []
img_names = []



f = open('templeRing/templeR_par.txt') 
folder = 'templeRing'

'''
folder = 'dino'
f = open('dino/dino_par.txt') 
'''


lines = f.readlines()
for line in lines[1:]:  
    elems = line.split(' ')
    img_names.append(elems[0])
    k = np.array([[elems[1], elems[2], elems[3]], [elems[4], elems[5], elems[6]], [elems[7], elems[8], elems[9]]]).astype(np.float64)
    rt = np.array([[elems[10], elems[11], elems[12], elems[19]], [elems[13], elems[14], elems[15], elems[20]], [elems[16], elems[17], elems[18], elems[21]]]).astype(np.float64())

    p = np.dot(k, rt)
    P.append(p)

pts_list = []
colors = []

for i in range(len(img_names)-1):
    try:
            
    # for i in range(len(img_names)-1):
        print('\r', 'Image:', str(i), end='')
        img1 = cv2.imread(folder+'/'+str(img_names[i]))
        img2 = cv2.imread(folder+'/'+str(img_names[i+1]))
        x1, x2 = siftMatching(img1, img2)
        
        for p in range(x1.shape[0]):        
            colors += [(img1[int(x1[p,1]), int(x1[p,0]), :] + img2[int(x2[p,1]), int(x2[p,0]), :])/2]
    
        # triangulatePoints requires 2xn arrays, so transpose the points
        pts = cv2.triangulatePoints(P[i], P[i+1], x1.T, x2.T)
        
    #     P[i+1], pts = bundle_adjustment(pts, x2.T, img2, P[i+1])
    #     pts = pts.T
        
        # however, homgeneous point is returned
        pts /= pts[3]  
        pts_list += list(pts.T)
    except:
        continue
pts_arr = np.array(pts_list)
colors = np.array(colors)
colors = np.flip(colors, 1)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib notebook

print('Triangulate 3d points - units in meters')
fig = plt.figure()
ax = Axes3D(fig)

X, Y, Z = np.reshape(pts_arr[:,0], (-1, 1)), np.reshape(pts_arr[:,1], (-1, 1)), np.reshape(pts_arr[:,2], (-1, 1))

# fig.set_size_inches(9,9)
plot_final = ax.scatter(X, Y, Z, c='#a1a1a1', s=3)
# plot_final = ax.plot_wireframe(X, Y, Z)

fig.set_facecolor('black')
ax.set_facecolor('black')
ax.grid(True)
ax.w_xaxis.set_pane_color((0.0, 0.0, 0.0, 0.0))
ax.w_yaxis.set_pane_color((0.0, 0.0, 0.0, 0.0))
ax.w_zaxis.set_pane_color((0.0, 0.0, 0.0, 0.0))

plt.show()


###############################################



###############################################
'''

# Pairwise image all combinations

pts_list = []

for i in range(len(img_names)-1):
    print('\r', 'Image:', str(i), end='')
    for j in range(i, min(i+3, len(img_names))):
        img1 = cv2.imread(folder+'/'+str(img_names[i]))
        img2 = cv2.imread(folder+'/'+str(img_names[j]))
        try:
            x1, x2 = siftMatching(img1, img2)

            # triangulatePoints requires 2xn arrays, so transpose the points
            pts = cv2.triangulatePoints(P[i], P[i+1], x1.T, x2.T)
            # however, homgeneous point is returned
            pts /= pts[3]  
            pts_list += list(pts.T)
        except:
            continue

pts_arr = np.array(pts_list)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib notebook

print('Triangulate 3d points - units in meters')
fig = plt.figure()
ax = Axes3D(fig)

# fig.set_size_inches(9,9)
plot_final = ax.scatter(pts_arr[:,0], pts_arr[:,1], pts_arr[:,2], color='grey', s=1)

fig.set_facecolor('black')
ax.set_facecolor('black')
ax.grid(True)
ax.w_xaxis.set_pane_color((0.0, 0.0, 0.0, 0.0))
ax.w_yaxis.set_pane_color((0.0, 0.0, 0.0, 0.0))
ax.w_zaxis.set_pane_color((0.0, 0.0, 0.0, 0.0))

plt.show()
'''

#"""### Fountain dataset"""


P = []
img_names = []

'''
for pfile in sorted(os.listdir('./fountain_11/fountain_dense_p/fountain_dense/urd')):
    img_names.append(pfile[:-2])
    f = open('fountain_11/fountain_dense_p/fountain_dense/urd/' + pfile)    
    lines = f.readlines()
    p = np.zeros((3,4))
    for i, line in enumerate(lines):
        elems = line.split(' ')
        p[i,:] = np.array([elems[0], elems[1], elems[2], elems[3]]).astype(np.float)
        
    P.append(p)

pts_list = []

for i in range(len(img_names)-1):
    print('\r', 'Image:', str(i), end='')
    img1 = cv2.imread('./fountain_11/fountain_dense/urd/'+str(img_names[i]))
    img2 = cv2.imread('./fountain_11/fountain_dense/urd/'+str(img_names[i+1]))
    x1, x2 = siftMatching(img1, img2)

    # triangulatePoints requires 2xn arrays, so transpose the points
    pts = cv2.triangulatePoints(P[i], P[i+1], x1.T, x2.T)
    # however, homgeneous point is returned
    pts /= pts[3]  
    pts_list += list(pts.T)

pts_arr = np.array(pts_list)

'''

'''
#folder = 'castle'
folder = 'fountain'
for pfile in sorted(os.listdir('./'+folder+'/'+folder+'_dense_p/urd')):
    img_names.append(pfile[:-2])
    f = open(''+folder+'/'+folder+'_dense_p/urd/' + pfile)    
    lines = f.readlines()
    p = np.zeros((3,4))
    for i, line in enumerate(lines):
        elems = line.split(' ')
        p[i,:] = np.array([elems[0], elems[1], elems[2], elems[3]]).astype(np.float)
        
    P.append(p)

pts_list = []

for i in range(len(img_names)-1):
    print('\r', 'Image:', str(i), end='')
    img1 = cv2.imread('./'+folder+'/'+folder+'_dense/urd/'+str(img_names[i]))
    img2 = cv2.imread('./'+folder+'/'+folder+'_dense/urd/'+str(img_names[i+1]))
    x1, x2 = siftMatching(img1, img2)

    # triangulatePoints requires 2xn arrays, so transpose the points
    pts = cv2.triangulatePoints(P[i], P[i+1], x1.T, x2.T)
    # however, homgeneous point is returned
    pts /= pts[3]  
    pts_list += list(pts.T)

pts_arr = np.array(pts_list)
# Commented out IPython magic to ensure Python compatibility.
# %matplotlib notebook



print('Triangulate 3d points - units in meters')
fig = plt.figure()
ax = Axes3D(fig)

X, Y, Z = np.reshape(pts_arr[:,0], (-1, 1)), np.reshape(pts_arr[:,1], (-1, 1)), np.reshape(pts_arr[:,2], (-1, 1))

# fig.set_size_inches(9,9)
plot_final = ax.scatter(X, Y, Z, c='#a1a1a1', s=3)
# plot_final = ax.plot_wireframe(X, Y, Z)

fig.set_facecolor('black')
ax.set_facecolor('black')
ax.grid(True)
ax.w_xaxis.set_pane_color((0.0, 0.0, 0.0, 0.0))
ax.w_yaxis.set_pane_color((0.0, 0.0, 0.0, 0.0))
ax.w_zaxis.set_pane_color((0.0, 0.0, 0.0, 0.0))

plt.show()

'''




