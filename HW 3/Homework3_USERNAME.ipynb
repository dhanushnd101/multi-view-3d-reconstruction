{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Homework3_USERNAME.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Uv_AZs3o90Oo"},"source":["#**ECE 4554/ ECE 5554 / Computer Vision**\n","This file contains Problem 5, which is the coding portion of Homework 3. Your job is to implement/modify the sections within this notebook that are marked with \"TO DO\".\n","\n","##**TO DO**: Enter your Virginia Tech Username (PID) here: ____________________ \n","\n","##**Honor Code reminder**\n","\n","This is not a \"team project\". Please review the Honor Code statement in the syllabus.  \n","\n","##**Submission guidelines** for the coding problems (Google Colab)\n","\n","1. Please verify that you have entered your Virginia Tech Username in all of the appropriate places.\n","2. After clicking Runtime->Run all, verify that all of your solutions are visible in this notebook.\n","3. Click File->Save near the top of the page to save the latest version of your notebook at Google Drive.\n","4. Verify that the last 2 cells have executed, creating a PDF version of this notebook at Google Drive. (Note: if you face difficulty with this step, please refer to https://pypi.org/project/notebook-as-pdf/)\n","5. Look at the PDF file and check that all of your solutions are displayed correctly there.\n","6. Download your notebook file and the PDF version to your laptop.\n","7. On your laptop, create a ZIP version of this notebook file. (Please don't include the separate data files.) Use file name Homework3_Code_USERNAME.zip, with your own Username.\n","6. For your PDF version, use file name Homework3_Notebook_USERNAME.pdf, with your own Username.\n","7. **Submit these 2 files and your PDF file for Problems 1-4 SEPARATELY to Canvas.** Do not zip them all together.\n","\n","##**Overview**\n","\n","This problem consists of the following 4 parts. By completing these parts, you will develop code that will automatically create a composite image from several overlapping images. Each part has equal weight in grading.\n","\n","a) 2D homography\n","\n","b) Image warping\n","\n","c) RANSAC using SIFT keypoints\n","\n","d) Image stitching"]},{"cell_type":"markdown","metadata":{"id":"6JAJCmmPnS0O"},"source":["# Environment setup"]},{"cell_type":"code","metadata":{"id":"5UZyFSREnaux"},"source":["# Mount your Google Drive to this notebook\n","# The purpose is to allow your code to access to your files\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LktsMf-_nX24"},"source":["# Change the directory to your own working directory\n","# Any files under your working directory are available to your code\n","# TO DO: enter the name of your directory\n","import os\n","os.chdir('/content/drive/MyDrive/ECE5554_Fall2021/Homework3')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDn8oAYGeZdb"},"source":["# The following is needed to allow the use of SIFT \n","# (need OpenCV version 4.5 or later)\n","# For a new installation, you may see a message:\n","#  \"You must restart the runtime in order to use newly installed versions.\" \n","#  One way to do this is to click \"Runtime\" -> \"Restart Runtime\"\n","# If you see an error message, you may need to run this step again, after running the \"Import\" block that follows\n","!pip install opencv-python==4.5.3.*"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2pUZSvqWnpEd"},"source":["# Import library modules\n","import sys\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# PIL is the Python Imaging Library\n","from PIL import Image  \n","# The following is a substitute for cv2.imshow, which Colab does not allow\n","from google.colab.patches import cv2_imshow\n","\n","print('Python version:', sys.version)\n","print('OpenCV version:', cv2.__version__)\n","print('NumPy version: ', np.__version__)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ic8DE-g5Q5Mv"},"source":["#Getting started\n","\n","Several image files were provided to you (Newman*.png, mandrill.tif, Rubiks_cube.jpg). Upload all of them to your working directory.\n","\n","The following functions are helpful for loading images into floating-point format, and for displaying images that are in that format.  Let's use those functions to visualize 3 separate images that we want to stitch together. Notice that you can adjust the size of the figure that is displayed.\n"]},{"cell_type":"code","metadata":{"id":"VjJLyVGO2Zpq"},"source":["def load_image(filename):\n","  img = np.asarray(Image.open(filename))\n","  img = img.astype(\"float32\")/255.0\n","  return img\n","\n","def show_image(img):\n","  fig = plt.figure()\n","  fig.set_size_inches(18, 10) # You can adjust the size of the displayed figure\n","  plt.imshow(img)\n","\n","left_img = load_image(\"Newman1.png\")\n","center_img = load_image(\"Newman2.png\")\n","right_img = load_image(\"Newman3.png\")\n","show_image(np.concatenate([left_img, center_img, right_img], axis=1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V2XlxO-lLo87"},"source":["Next, verify that you can use OpenCV tools to detect SIFT-based keypoints. These library functions allow for many options. For example, if you change the `nfeatures` parameter for `SIFT_create`, you'll see different numbers of detected keypoints. You may want to experiment with these parameters later."]},{"cell_type":"code","metadata":{"id":"k0lKIlVEIpFC"},"source":["def testSIFT(img1):\n","  sift = cv2.SIFT_create(nfeatures=500)\n","  kp = sift.detect(img1, None)\n","  img1=cv2.drawKeypoints(img1, kp, None, color=(0, 255, 255))\n","  \n","  fig = plt.figure()\n","  fig.set_size_inches(18,10) # You can adjust the size of the displayed figure\n","  plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n","\n","\n","img = cv2.imread(\"Newman1.png\", cv2.IMREAD_COLOR)\n","testSIFT(img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ut59RaQX5gFY"},"source":["#Part (a):  2D homography\n","\n","Implement the 2 functions that are shown in the next code block. (OpenCV has a findHomography() function, and other related functions, but for this assignment you must write your own version.)\n","\n","1.   **compute_homography(src, dst)** receives two matrices, each of size Nx2. Each matrix contains N two-dimensional points. For each value of i, src[i] and dst[i] are corresponding points from two different images. The function should return the homography matrix H of size 3x3 that maps every point from the source (src) to the destination (dst).   Guidance: You may assume that N is at least 4. You can set up the problem in a matrix-based, least-squares format. (A somewhat similar problem is in the lecture slides on page 40 of packet 5.) Helpful functions are `np.linalg.eig()` and `np.linalg.eigh()` for computing eigenvalues and eigenvectors. The latter function will prevent warnings due to small imaginary values if you are working with matrices that are real and symmetric. \n","2.   **apply_homography(src, H)** receives points in matrix src (an Nx2 matrix), and a homography transformation H (a 3x3 matrix). This function should use the homography matrix to transform each point in src to a new destination point. Store the resulting points in matrix dst, which is the same size as src. The function should return dst. Guidance: remember to use homogeneous coordinates when implementing this transformation.\n","\n"]},{"cell_type":"code","metadata":{"id":"VG1HInZWLG6b"},"source":["def compute_homography(src, dst):\n","  '''Computes the homography from src to dst.\n","   Input:\n","    src: source points, shape (N, 2), where N >= 4\n","    dst: destination points, shape (N, 2)\n","   Output:\n","    H: homography from source points to destination points, shape (3, 3)\n","\n","   TO DO: Implement the compute_homography function\n","  '''\n","  # The following line is just a place-holder\n","  H = np.matrix('1, 0, 0; 0, 1, 0; 0, 0, 1')\n","  \n","  return H\n","\n","\n","def apply_homography(src, H):\n","  '''Applies a homography H to the source points.\n","   Input:\n","      src: source points, shape (N, 2)\n","      H: homography from source points to destination points, shape (3, 3)\n","   Output:\n","     dst: destination points, shape (N, 2)\n","\n","   TO DO: Implement the apply_homography function\n","  '''\n","  dst = np.zeros([src.shape[0], 2])\n","  \n","  \n","  return dst"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"APm8HyaaC1Jz"},"source":["You do not need to change the following function. It will test your homography code, and should help you in debugging. Corresponding points are placed in src_pts and dst_pts. If your homography code is correct, it should map the points given in test_pts to locations that are close to the points given in match_pts_correct. If you have correctly implemented compute_homography() and apply_homography(), then the printed difference values should be close to 0. (A small difference, such as 0.001, should be acceptable.)"]},{"cell_type":"code","metadata":{"id":"EwrIOOW2fYck"},"source":["def test_homography():\n","  src_pts = np.matrix('0, 0; 1, 0; 1, 1; 0, 1')\n","  dst_pts = np.matrix('5, 4; 7, 4; 7, 5; 6, 6')\n","  H = compute_homography(src_pts, dst_pts)\n","  test_pts = np.matrix('0,  0; 1, 0; 1, 1; 0, 1')\n","  match_pts = apply_homography(test_pts, H)\n","  match_pts_correct = np.matrix('5, 4; 7, 4; 7, 5; 6, 6')\n","  print('Your 1st solution differs from our solution by: %f'\n","    % np.square(match_pts - match_pts_correct).sum())\n","  \n","  src_pts = np.matrix('0, 0; 1, 0; 1, 1; 0, 1; 2, 3')\n","  dst_pts = np.matrix('5, 4; 7, 4; 7, 5; 6, 6; 7.25, 5.5')\n","  H = compute_homography(src_pts, dst_pts)\n","  test_pts = np.matrix('0,  0; 1, 0; 1, 1; 0, 1')\n","  match_pts = apply_homography(test_pts, H)\n","  match_pts_correct = np.matrix('5, 4; 7, 4; 7, 5; 6, 6')\n","  print('Your 2nd solution differs from our solution by: %f'\n","    % np.square(match_pts - match_pts_correct).sum())\n","  \n","  src_pts = np.matrix('347, 313; 502, 341; 386, 571; 621, 508')\n","  dst_pts = np.matrix('274, 286; 436, 305; 305, 527; 615, 506')\n","  H = compute_homography(src_pts, dst_pts)\n","  test_pts = np.matrix('259, 505; 350, 371; 400, 675; 636, 104')\n","  match_pts = apply_homography(test_pts, H)\n","  match_pts_correct = np.matrix('195.13761083, 448.12645033;'\n","    '275.27269386, 336.54819916;'\n","    '317.37663747, 636.78403426;'\n","    '618.50438823, 28.78963905')\n","  print('Your 3rd solution differs from our solution by: %f'\n","    % np.square(match_pts - match_pts_correct).sum())\n","  \n","test_homography()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vUnyYXVxEABo"},"source":["#Part (b):  Image warping using a 2D homography\n","\n","Implement the following function so that it performs image warping from a source image (src_img) to a newly created destination image (dst_img). Do not use any additional OpenCV functions. The homography H that is provided indicates a desired mapping from src_img to dst_img. To prevent gaps in the output image, however, it is suggested that your implementation should iterate over all pixels in dst_img. In that case, your code should use the *inverse* of H to find values in src_img as it iterates over dst_img."]},{"cell_type":"code","metadata":{"id":"lyxARzWBhZzF"},"source":["def warp_img(src_img, H, dst_img_size):\n","  '''Warping of a source image using a homography.\n","   Input:\n","      src_img: source image with shape (m, n, 3)\n","      H: homography, with shape (3, 3), from source image to destination image\n","      dst_img_size: height and width of destination image; shape (2,)\n","   Output:\n","      dst_img: destination image; height and width specified by dst_img_size parameter\n","\n","   TO DO: Implement the warp_img function.\n","  '''\n","  dst_img = np.zeros([dst_img_size[0], dst_img_size[1], 3])\n","\n","  \n","  return dst_img\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X5WVHX7zgbBA"},"source":["Use the functions below to help debug your implementation. You do not need to modify these functions. If your code is correct, the output here should show a  mandrill image that has been warped to overlay the blue side of a Rubik's cube."]},{"cell_type":"code","metadata":{"id":"88JvFeWIVKVi"},"source":["def binary_mask(img):\n","  '''Create a binary mask of the image content.\n","   Input:\n","    img: source image, shape (m, n, 3)\n","   Output:\n","    mask: image of shape (m, n) and type 'int'. For pixel [i, j] of mask, \n","      if pixel [i, j] in img is nonzero in any channel, assign 1 to mask[i, j]. \n","      Else, assign 0 to mask[i, j].\n","  '''\n","  mask = (img[:, :, 0] > 0) | (img[:, :, 1] > 0) | (img[:, :, 2] > 0)\n","  mask = mask.astype(\"int\")\n","  return mask\n","\n","def test_warp():\n","  src_img = load_image('mandrill.tif')\n","  canvas_img = load_image('Rubiks_cube.jpg')\n","\n","  # The following are corners of the mandrill image\n","  src_pts = np.matrix('0, 0; 0, 511; 511, 511; 511, 0')\n","  # The following are corners of the blue face of the Rubik's cube\n","  canvas_pts = np.matrix('218, 238; 225, 560; 490, 463; 530, 178')\n","\n","  # The following was used during debugging\n","  # print(canvas_pts)\n","  # test_x=218\n","  # test_y=238\n","  # cv2.circle(canvas_img, (218, 238), 4, (255, 0, 0), thickness=10)\n","\n","  H = compute_homography(src_pts, canvas_pts)\n","  dst_img = warp_img(src_img, H, [canvas_img.shape[0], canvas_img.shape[1]])\n","  dst_mask = 1 - binary_mask(dst_img)\n","  dst_mask = np.stack((dst_mask,) * 3, -1)\n","  out_img = np.multiply(canvas_img, dst_mask) + dst_img\n","  \n","  dsize = (600, 600) # width and height of canvas_im\n","  src_smaller = cv2.resize(src_img, dsize, interpolation=cv2.INTER_AREA)\n","  \n","  warped_img = np.concatenate((src_smaller, canvas_img, out_img), axis=1)\n","  show_image(np.clip(warped_img, 0, 1))\n","\n","test_warp()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MpLCobsqG348"},"source":["#Part (c) RANSAC using SIFT keypoints\n","\n","You have already confirmed that you can detect SIFT-based keypoints. Next, verify that you can use a matching technique from OpenCV that tries to detect corresponding keypoints between 2 images. The code should display the correspondences and draw lines between them.\n","\n","By the way, cv2.BFmatcher() is OpenCV's \"brute force\" matcher. More description is given in \n","https://github.com/abidrahmank/OpenCV2-Python-Tutorials/blob/master/source/py_tutorials/py_feature2d/py_matcher/py_matcher.rst"]},{"cell_type":"code","metadata":{"id":"RWudCkU4oCum"},"source":["def genSIFTMatchPairs(img1, img2):\n","  sift = cv2.SIFT_create()\n","  #kp = sift.detect(img1, None)\n","  #kp = cv2.SIFT(edgeThreshold=10)\n","  kp1, des1 = sift.detectAndCompute(img1, None)\n","  kp2, des2 = sift.detectAndCompute(img2, None)\n","  bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n","  matches = bf.match(des1, des2)\n","  matches = sorted(matches, key = lambda x:x.distance)\n","\n","  pts1 = np.zeros((250, 2))\n","  pts2 = np.zeros((250, 2))\n","  for i in range(250):\n","    pts1[i,:] = kp1[matches[i].queryIdx].pt\n","    pts2[i,:] = kp2[matches[i].trainIdx].pt\n","\n","  return pts1, pts2, matches[:250], kp1, kp2\n","\n","def test_matches():\n","  img1 = cv2.imread('Newman1.png')\n","  img2 = cv2.imread('Newman3.png')\n","  pts1, pts2, matches1to2, kp1, kp2 = genSIFTMatchPairs(img1, img2)\n","\n","  # In the following, parameter flags=2 will remove unmatched points from the display\n","  matching_result = cv2.drawMatches(img1, kp1, img2, kp2, matches1to2, None, flags=2,\n","    matchColor = (255, 255, 0), singlePointColor=(0, 0, 255))\n","  \n","  fig = plt.figure()\n","  fig.set_size_inches(18,10) # You can adjust the size of the displayed figure\n","  plt.imshow(cv2.cvtColor(matching_result, cv2.COLOR_BGR2RGB))\n","\n","\n","test_matches()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qxuaGPNKu8nb"},"source":["Notice that some of the matches from the previous step are not correct. It is possible that those false matches could act as outliers in your homography estimation. In that case we would expect a poor result in any composite image that we create. \n","\n","As discussed during lectures, the RANSAC algorithm is a popular way to deal with outliers during model fitting. Here you must implement your own function that uses the RANSAC approach to compute a homography H. "]},{"cell_type":"code","metadata":{"id":"eTK0nCbXinUT"},"source":["def RANSAC(Xs, Xd, max_iter, eps):\n","  '''Find correspondences between two sets of points using the RANSAC algorithm.\n","   Input:\n","    Xs: the first set of points (source), shape [n, 2]\n","    Xd: the second set of points (destination) matched to the first set, shape [n, 2] \n","    max_iter: max number of iterations that RANSAC should perform\n","    eps: tolerance of RANSAC\n","   Output:\n","    inliers_id: the indices of matched pairs when using the homography given by RANSAC\n","    H: the computed homography, shape [3, 3]\n","\n","   TO DO: Implement the RANSAC function.\n","  '''\n","  H = np.zeros([3,3])\n","  inliers_id = []\n","\n","\n","\n","  return inliers_id, H\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FSqJUbo4xxRj"},"source":["Now we can look at the matches between keypoints after using your RANSAC implementation. You do not need to modify the code in the next block. If you implemented RANSAC correctly, hopefully all of the incorrect matches have been discarded in the following output."]},{"cell_type":"code","metadata":{"id":"L_o1dWEFxyq1"},"source":["def test_ransac():\n","  img1 = cv2.imread('Newman1.png')\n","  img2 = cv2.imread('Newman3.png')\n","  pts1, pts2, matches1to2, kp1, kp2 = genSIFTMatchPairs(img1, img2)\n","  \n","  inliers_idx, H = RANSAC(pts1, pts2, 500, 50)\n","  new_matches = []\n","  for i in range(len(inliers_idx)):\n","    new_matches.append(matches1to2[inliers_idx[i]])\n","\n","  matching_result = cv2.drawMatches(img1, kp1, img2, kp2, new_matches, None, flags=2, \n","                                    matchColor = (255, 255, 0), singlePointColor=(0, 0, 255))\n","\n","  fig = plt.figure()\n","  fig.set_size_inches(18, 10) # You can adjust the size of the displayed figure\n","  plt.imshow(cv2.cvtColor(matching_result, cv2.COLOR_BGR2RGB))\n","\n","test_ransac()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j0a3cecK1oFE"},"source":["#Part (d):  Image stitching.\n","\n","We are now ready to create a panorama from the three images that were shown at the beginning. The stitch_img() function below receives a Python list of images, which the code should stitch together to form one large image.\n","You must use the functions that you have written to create the panorama. \n","\n","We do not expect the result to be perfect, partly because some lens distortion is always present and it will prevent the homography from aligning things perfectly. However, for full credit, try to write code that will stitch the images together with very little noticable seam."]},{"cell_type":"code","metadata":{"id":"HE6YZLyuOvJZ"},"source":["\n","def stitch_img(imgs):\n","  '''Stitch a list of images together.\n","   Input:\n","    imgs: a list of images.\n","   Output:\n","    stitched_img: a single stiched image.\n","  \n","   TO DO: implement the stitch_img function.\n","  '''\n","  # the following line is just a placeholder\n","  img0 = imgs[0]\n","\n","  return img0\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Iz4Pv-Ta3z6b"},"source":["Use the following code to test your implementation. This code just reads in the images, calls your stitch_img() function, and plots the results.\n"]},{"cell_type":"code","metadata":{"id":"VUTZQYeFbP_K"},"source":["left_img = cv2.imread(\"Newman1.png\")\n","center_img = cv2.imread(\"Newman2.png\")\n","right_img = cv2.imread(\"Newman3.png\")\n","\n","final_img = stitch_img([center_img, left_img, right_img])\n","\n","fig = plt.figure()\n","fig.set_size_inches(25,10) # You can adjust the size of the displayed figure\n","plt.imshow(cv2.cvtColor(final_img.astype(\"uint8\"), cv2.COLOR_BGR2RGB))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2OXqjtZsGV02"},"source":["Finally, use 3 or more photos of your own to create a panorama. It is suggested that you take new photos using your camera (e.g., with your phone or laptop). Remember to stand in place and try to rotate the camera about its point of projection. (If the camera position changes, then the transformation between 2 images is no longer a homography.)\n","\n","**Please include these new photos as part of your HW3 submission.** We would like to select the best panoramas (as decided by the graders) to show during a lecture. (If you prefer that we do not show your photos to the class, that is fine. In that case, please tell us using a comment at the top of the following code block.) To reduce computation time, it is acceptable to resize your images down to a smaller size before processing them. You could consider using `cv2.resize()` for that purpose. For example, the provided Newman Library images were reduced to 800x600 from much larger dimensions.\n","\n"]},{"cell_type":"code","metadata":{"id":"_Bkur9ieH204"},"source":["# TO DO: Load your own images here and create a panorama. \n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9oMvIzi4nxPo"},"source":["---\n","# Creating a PDF version of your current notebook"]},{"cell_type":"code","metadata":{"id":"euPVsDQfn5jq"},"source":["#The following two installation steps are needed to generate a PDF version of the notebook\n","#(These lines are needed within Google Colab, but are not needed within a local version of Jupyter notebook)\n","!apt-get -qq install texlive texlive-xetex texlive-latex-extra pandoc \n","!pip install --quiet pypandoc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8UGtiNYsoIKJ"},"source":["# TO DO: Provide the full path to your Jupyter notebook file\n","!jupyter nbconvert --to PDF \"/content/drive/MyDrive/ECE5554_Fall2021/Homework3/Homework3_testing.ipynb\""],"execution_count":null,"outputs":[]}]}